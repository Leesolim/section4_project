{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U efficientnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zwb6WuGI4SHl",
        "outputId": "d089d167-5d79-4b3d-b7fd-91e329a786c1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting efficientnet\n",
            "  Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.8/dist-packages (from efficientnet) (0.18.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.8/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.21.6)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet) (1.3.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet) (2.9.0)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet) (1.7.3)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet) (2.6.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet) (7.1.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet) (2021.11.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.4.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.15.0)\n",
            "Installing collected packages: keras-applications, efficientnet\n",
            "Successfully installed efficientnet-1.1.1 keras-applications-1.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1Ob_AlDhHAD8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b744bab5-cff8-4d4b-bb1e-03d727044f76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb7_notop.h5\n",
            "258076736/258076736 [==============================] - 8s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        " \n",
        "from tensorflow.keras.applications.efficientnet import EfficientNetB7\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input, decode_predictions\n",
        " \n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model # This is the functional API\n",
        " \n",
        "efficientnet = EfficientNetB7(weights='imagenet', include_top=False) # 모델에서 Fully Connected layer 부분을 제거해주는 역할"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIJBx567HhxD",
        "outputId": "bae2065a-40d1-431e-c7da-32eb56477b72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2HPwx8O9Hhz1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/apple'\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "train_fresh_dir = os.path.join(train_dir, 'fresh')\n",
        "train_rotten_dir = os.path.join(train_dir, 'rotten')\n",
        "\n",
        "test_apple_dir = os.path.join(base_dir, 'test_apple')\n",
        "test_apple_fresh_dir = os.path.join(test_apple_dir, 'fresh')\n",
        "test_apple_rotten_dir = os.path.join(test_apple_dir, 'rotten')\n",
        "\n",
        "test_banana_dir = os.path.join(base_dir, 'test_banana')\n",
        "test_banana_fresh_dir = os.path.join(test_banana_dir, 'fresh')\n",
        "test_banana_rotten_dir = os.path.join(test_banana_dir, 'rotten')\n",
        "\n",
        "test_orange_dir = os.path.join(base_dir, 'test_orange')\n",
        "test_orange_fresh_dir = os.path.join(test_orange_dir, 'fresh')\n",
        "test_orange_rotten_dir = os.path.join(test_orange_dir, 'rotten')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tn44knjAHh2z",
        "outputId": "d90561eb-c519-4a9b-a7c3-c3371731695b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Screen Shot 2018-06-08 at 4.59.36 PM.png', 'Screen Shot 2018-06-08 at 4.59.49 PM.png', 'Screen Shot 2018-06-08 at 4.59.57 PM.png', 'Screen Shot 2018-06-08 at 5.00.03 PM.png', 'Screen Shot 2018-06-08 at 5.00.12 PM.png', 'Screen Shot 2018-06-08 at 5.00.18 PM.png', 'Screen Shot 2018-06-08 at 5.00.26 PM.png', 'Screen Shot 2018-06-08 at 5.00.35 PM.png', 'Screen Shot 2018-06-08 at 5.00.43 PM.png', 'Screen Shot 2018-06-08 at 5.00.50 PM.png']\n",
            "['Screen Shot 2018-06-07 at 2.15.20 PM.png', 'Screen Shot 2018-06-07 at 2.15.50 PM.png', 'Screen Shot 2018-06-07 at 2.16.18 PM.png', 'Screen Shot 2018-06-07 at 2.16.41 PM.png', 'Screen Shot 2018-06-07 at 2.17.15 PM.png', 'Screen Shot 2018-06-07 at 2.17.25 PM.png', 'Screen Shot 2018-06-07 at 2.18.13 PM.png', 'Screen Shot 2018-06-07 at 2.18.57 PM.png', 'Screen Shot 2018-06-07 at 2.19.15 PM.png', 'Screen Shot 2018-06-07 at 2.19.37 PM.png']\n"
          ]
        }
      ],
      "source": [
        "train_fresh_fnames = os.listdir(train_fresh_dir)\n",
        "train_fresh_fnames.sort()\n",
        "print(train_fresh_fnames[:10])\n",
        "\n",
        "train_rotten_fnames = os.listdir(train_rotten_dir)\n",
        "train_rotten_fnames.sort()\n",
        "print(train_rotten_fnames[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9NtvDJXHh5I",
        "outputId": "65a7c482-9c67-460e-c8b8-54f36d1ef620"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total training fresh images: 1693\n",
            "total training rotten images: 2342\n",
            "total test_apple fresh images: 395\n",
            "total test_apple rotten images: 601\n",
            "total test_banana fresh images: 381\n",
            "total test_banana rotten images: 530\n",
            "total test_orange fresh images: 388\n",
            "total test_orange rotten images: 403\n"
          ]
        }
      ],
      "source": [
        "print('total training fresh images:', len(os.listdir(train_fresh_dir)))\n",
        "print('total training rotten images:', len(os.listdir(train_rotten_dir)))\n",
        "print('total test_apple fresh images:', len(os.listdir(test_apple_fresh_dir)))\n",
        "print('total test_apple rotten images:', len(os.listdir(test_apple_rotten_dir)))\n",
        "print('total test_banana fresh images:', len(os.listdir(test_banana_fresh_dir)))\n",
        "print('total test_banana rotten images:', len(os.listdir(test_banana_rotten_dir)))\n",
        "print('total test_orange fresh images:', len(os.listdir(test_orange_fresh_dir)))\n",
        "print('total test_orange rotten images:', len(os.listdir(test_orange_rotten_dir)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "f8UBaGyOHh7f"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "img_input = layers.Input(shape=(224*224*3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juIvknTnHh-G",
        "outputId": "2b6aa9b7-ab08-434d-c6a4-62db2ca1a769"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4035 images belonging to 2 classes.\n",
            "Found 996 images belonging to 2 classes.\n",
            "Found 911 images belonging to 2 classes.\n",
            "Found 791 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_apple_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_banana_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_orange_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,  \n",
        "        target_size=(224, 224),\n",
        "        batch_size=256,\n",
        "        classes = ['fresh','rotten'],\n",
        "        class_mode=\"binary\")\n",
        "\n",
        "test_apple_generator = test_apple_datagen.flow_from_directory(\n",
        "        test_apple_dir,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=256,\n",
        "        classes = ['fresh', 'rotten'],\n",
        "        class_mode=\"binary\")\n",
        "\n",
        "\n",
        "test_banana_generator = test_banana_datagen.flow_from_directory(\n",
        "        test_banana_dir,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=256,\n",
        "        classes = ['fresh', 'rotten'],\n",
        "        class_mode=\"binary\")\n",
        "\n",
        "test_orange_generator = test_orange_datagen.flow_from_directory(\n",
        "        test_orange_dir,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=256,\n",
        "        classes = ['fresh', 'rotten'],\n",
        "        class_mode=\"binary\")\n",
        "\n",
        "\n",
        "# 전체데이터 : 배치사이즈 수정 필요\n",
        "# resnet50 input image size ; 224 x 224 x 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "0lTGOc4oMWEP"
      },
      "outputs": [],
      "source": [
        "for layer in efficientnet.layers:\n",
        "    layer.trainable = False\n",
        "# ResNet50 레이어들의 파라미터를 학습하지 않도록 설정합니다.\n",
        "# 이렇게 설정된 매개 변수는 역전파를 통해 오차 정보가 전파 되더라도 파라미터가 업데이트 되지 않습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Waj9pK2gMWG6"
      },
      "outputs": [],
      "source": [
        "x = efficientnet.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "model = Model(efficientnet.input, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "uXZKp7vqMWJ1"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsUeeURnQ1pP",
        "outputId": "38a3a21b-8ccc-4704-bd21-37ca5b3b8ed0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "16/16 [==============================] - 64s 3s/step - loss: 0.7432 - accuracy: 0.5192\n",
            "Epoch 2/30\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.6889 - accuracy: 0.5623\n",
            "Epoch 3/30\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.6805 - accuracy: 0.5812\n",
            "Epoch 4/30\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.6786 - accuracy: 0.5814\n",
            "Epoch 5/30\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.6772 - accuracy: 0.5824\n",
            "Epoch 6/30\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.6777 - accuracy: 0.5849\n",
            "Epoch 7/30\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.6790 - accuracy: 0.5817\n",
            "Epoch 8/30\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.6770 - accuracy: 0.5836\n",
            "Epoch 9/30\n",
            "16/16 [==============================] - 47s 3s/step - loss: 0.6765 - accuracy: 0.5881\n",
            "Epoch 10/30\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.6743 - accuracy: 0.5864\n",
            "Epoch 11/30\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.6730 - accuracy: 0.5965\n",
            "Epoch 12/30\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.6751 - accuracy: 0.5839\n",
            "Epoch 13/30\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.6801 - accuracy: 0.5762\n",
            "Epoch 14/30\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.6783 - accuracy: 0.5725\n",
            "Epoch 15/30\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.6736 - accuracy: 0.5841\n",
            "Epoch 16/30\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.6773 - accuracy: 0.5859\n",
            "Epoch 17/30\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.6840 - accuracy: 0.5584\n",
            "Epoch 18/30\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.6766 - accuracy: 0.5727\n",
            "Epoch 19/30\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.6726 - accuracy: 0.5849\n",
            "Epoch 20/30\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.6740 - accuracy: 0.5849\n",
            "Epoch 21/30\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.6729 - accuracy: 0.5916\n",
            "Epoch 22/30\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.6743 - accuracy: 0.5888\n",
            "Epoch 23/30\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.6731 - accuracy: 0.5980\n",
            "Epoch 24/30\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.6737 - accuracy: 0.5841\n",
            "Epoch 25/30\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.6676 - accuracy: 0.5928\n",
            "Epoch 26/30\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.6681 - accuracy: 0.5963\n",
            "Epoch 27/30\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.6710 - accuracy: 0.5923\n",
            "Epoch 28/30\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.6686 - accuracy: 0.5948\n",
            "Epoch 29/30\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.6703 - accuracy: 0.5953\n",
            "Epoch 30/30\n",
            "16/16 [==============================] - 46s 3s/step - loss: 0.6664 - accuracy: 0.5958\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "      train_generator, \n",
        "      epochs=30,\n",
        "      verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itbPnkQDQ1xP",
        "outputId": "b6e86309-ae19-4b5c-cf98-982650e2b456"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 16s 3s/step - loss: 0.6518 - accuracy: 0.6456\n",
            "loss_and_metrics_apple : [0.6518474221229553, 0.6455823183059692]\n"
          ]
        }
      ],
      "source": [
        "loss_and_metrics_apple = model.evaluate(test_apple_generator)\n",
        "print('loss_and_metrics_apple : ' + str(loss_and_metrics_apple))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "2Ka0QNBOQ10Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbc63a50-6124-4e68-a811-7f2e573a27a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 11s 2s/step - loss: 0.6823 - accuracy: 0.5851\n",
            "loss_and_metrics_banana : [0.6822525262832642, 0.585071325302124]\n"
          ]
        }
      ],
      "source": [
        "loss_and_metrics_banana = model.evaluate(test_banana_generator)\n",
        "print('loss_and_metrics_banana : ' + str(loss_and_metrics_banana))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_and_metrics_orange = model.evaluate(test_orange_generator)\n",
        "print('loss_and_metrics_orange : ' + str(loss_and_metrics_orange))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltlergFu_zp8",
        "outputId": "829a5b08-c2aa-4c7b-ab16-1017ad6fa1d1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 10s 2s/step - loss: 0.7047 - accuracy: 0.5259\n",
            "loss_and_metrics_orange : [0.7046830654144287, 0.525916576385498]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 저장하기\n",
        "from keras.models import load_model\n",
        "model.save('apple_EfficientNetB7_Dense256_epoch30.h5')\n",
        "\n",
        "# 2. 모델 불러오기\n",
        "# from keras.models import load_model\n",
        "# model = load_model('모델파일명.h5')"
      ],
      "metadata": {
        "id": "LP2fGcMszCfg"
      },
      "execution_count": 26,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}